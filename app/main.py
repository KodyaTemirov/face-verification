#!/usr/bin/env python3
"""
Face Comparison Service - MagFace Edition with Anti-Spoofing & Telegram
–°–µ—Ä–≤–∏—Å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MagFace –º–æ–¥–µ–ª–∏, –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ –∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
"""
import base64
import io
import logging
import os
import time
from datetime import datetime
from typing import Dict, Optional, List, Union

import cv2
import insightface
import numpy as np
from PIL import Image
from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn
import requests
from urllib.parse import urlparse
import sys
import tempfile
import onnxruntime

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    from .config import config
    from .telegram_notifier import telegram_notifier
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∏ –µ—Å–ª–∏ –º–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
    class Config:
        TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
        TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")
        TELEGRAM_ENABLED = os.getenv("TELEGRAM_ENABLED", "true").lower() == "true"
        NOTIFY_ON_SPOOFING = True
        NOTIFY_ON_LOW_CONFIDENCE = True
        NOTIFY_ON_ERRORS = True
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞
        ANTISPOOF_THRESHOLD = 0.3  # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–π –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ä–æ–≥
        ANTISPOOF_STRICT_THRESHOLD = 0.7  # –°—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è —è–≤–Ω—ã—Ö –ø–æ–¥–¥–µ–ª–æ–∫
        ANTISPOOF_MIN_CONFIDENCE = 0.4  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        LOW_QUALITY_IMAGE_THRESHOLD = 0.2  # –ü–æ—Ä–æ–≥ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        HIGH_QUALITY_IMAGE_THRESHOLD = 0.5  # –ü–æ—Ä–æ–≥ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        
        @classmethod
        def is_telegram_configured(cls):
            return bool(cls.TELEGRAM_BOT_TOKEN and cls.TELEGRAM_CHAT_ID and cls.TELEGRAM_ENABLED)
    
    config = Config()
    
    class TelegramNotifier:
        def __init__(self):
            self.enabled = config.is_telegram_configured()
        def send_message(self, message, parse_mode=None): 
            if not self.enabled: 
                logger.warning("üì¥ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã")
                return False
            try:
                logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è...")
                url = f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}/sendMessage"
                data = {"chat_id": config.TELEGRAM_CHAT_ID, "text": message}
                if parse_mode:
                    data["parse_mode"] = parse_mode
                response = requests.post(url, json=data, timeout=10)
                
                if response.status_code == 200:
                    logger.info("‚úÖ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
                    return True
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram: {response.status_code} - {response.text}")
                    return False
            except Exception as e:
                logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ Telegram: {str(e)}")
                return False
        def notify_spoofing_detected(self, image_info, confidence):
            if config.NOTIFY_ON_SPOOFING:
                message = f"üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ê –ü–û–î–î–ï–õ–ö–ê!\nüì∏ {image_info}\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}\n‚è∞ {datetime.now().strftime('%H:%M:%S')}"
                self.send_message(message)
        def notify_comparison_result(self, similarity, verified, processing_time, 
                                   image1_url=None, image2_url=None, 
                                   antispoof_results=None, threshold=0.5):
            status = "‚úÖ –í–ï–†–ò–§–ò–¶–ò–†–û–í–ê–ù" if verified else "‚ùå –ù–ï –í–ï–†–ò–§–ò–¶–ò–†–û–í–ê–ù"
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            message = f"üìä –°–†–ê–í–ù–ï–ù–ò–ï –õ–ò–¶\n{status}\nüéØ –°—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.2%}\n‚è±Ô∏è –í—Ä–µ–º—è: {processing_time:.3f}—Å"
            
            # –ï—Å–ª–∏ –Ω–µ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É
            if not verified:
                reasons = []
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω—É: –Ω–∏–∑–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
                if similarity < threshold:
                    reasons.append(f"üîç –ù–∏–∑–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ({similarity:.1%} < {threshold:.1%})")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                if antispoof_results:
                    img2_spoof = antispoof_results.get('image2', {})
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ç–æ—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å–ø—É—Ñ–∏–Ω–≥
                    # –ë–ª–æ–∫–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø–æ–¥–¥–µ–ª–∫–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞
                    if not img2_spoof.get('is_real', True):
                        confidence = img2_spoof.get('confidence', 0) * 100
                        model_used = img2_spoof.get('model_used', 'unknown')
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                        if img2_spoof.get('confidence', 0) >= config.ANTISPOOF_MIN_CONFIDENCE:
                            reasons.append(f"üö´ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2: –ø–æ–¥–¥–µ–ª–∫–∞ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1f}%, –º–æ–¥–µ–ª—å: {model_used})")
                        else:
                            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º
                            logger.info(f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø–æ–¥–¥–µ–ª–∫–µ ({confidence:.1f}%), –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                
                if reasons:
                    message += f"\n\nüî¥ –ü–†–ò–ß–ò–ù–´ –û–¢–ö–õ–û–ù–ï–ù–ò–Ø:\n" + "\n".join(reasons)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
            if image1_url or image2_url:
                message += f"\n\nüñºÔ∏è –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:"
                if image1_url:
                    message += f"\nüìé –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1:\n{image1_url}"
                if image2_url:
                    message += f"\nüìé –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2:\n{image2_url}"
            
            self.send_message(message)
        def notify_error(self, error_type, error_message):
            if config.NOTIFY_ON_ERRORS:
                message = f"üî¥ –û–®–ò–ë–ö–ê\nüè∑Ô∏è {error_type}\nüìù {error_message}\n‚è∞ {datetime.now().strftime('%H:%M:%S')}"
                self.send_message(message)
    
    telegram_notifier = TelegramNotifier()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('./logs/face-comparison.log')
    ]
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
app_stats = {
    "total_comparisons": 0,
    "successful_comparisons": 0,
    "failed_comparisons": 0,
    "total_antispoof_checks": 0,
    "real_faces": 0,
    "fake_faces": 0,
    "start_time": datetime.now(),
    "response_times": []
}

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è API
class CompareRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–∏—Ü"""
    image1: str  # base64 encoded image –∏–ª–∏ URL
    image2: str  # base64 encoded image –∏–ª–∏ URL
    image1_type: str = "base64"  # "base64" –∏–ª–∏ "url"
    image2_type: str = "base64"  # "base64" –∏–ª–∏ "url"
    model: str = "MagFace-R100"
    metric: str = "cosine"
    threshold: float = 0.5
    enable_antispoof: bool = True  # –í–∫–ª—é—á–∏—Ç—å –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

class CompareResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü"""
    verified: bool
    distance: float
    similarity: float
    similarity_percentage: float
    threshold: float
    model: str
    metric: str
    processing_time: float
    timestamp: str
    faces_detected: Dict[str, int]
    antispoof_results: Optional[Dict[str, Dict]] = None

class HealthResponse(BaseModel):
    """–û—Ç–≤–µ—Ç health check"""
    status: str
    timestamp: str
    version: str = "2.0.0"
    model: str = "MagFace-R100 with Anti-Spoofing"
    models_loaded: bool = True
    uptime_seconds: float
    total_comparisons: int
    total_antispoof_checks: int
    gpu_available: bool
    memory_info: Optional[Dict] = None

class SystemInfoResponse(BaseModel):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ"""
    service_name: str
    version: str
    model: str
    available_models: List[str]
    supported_formats: List[str]
    gpu_info: Dict[str, bool]
    configuration: Dict[str, str]
    antispoof_enabled: bool

# –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞
class AntiSpoofProcessor:
    def __init__(self, model_path: str = "./models/asv_antispoof_r34.onnx"):
        self.model_path = model_path
        self.session = None
        self.input_size = (128, 128)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞"""
        try:
            if not os.path.exists(self.model_path):
                logger.warning(f"‚ùå –ú–æ–¥–µ–ª—å –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
                logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ (–≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç '—Ä–µ–∞–ª—å–Ω–æ–µ –ª–∏—Ü–æ')")
                return False
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª-–∑–∞–≥–ª—É—à–∫–∞
            if os.path.getsize(self.model_path) < 1000:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –º–µ–Ω—å—à–µ 1KB
                logger.warning(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª: {self.model_path}")
                logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ (–≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç '—Ä–µ–∞–ª—å–Ω–æ–µ –ª–∏—Ü–æ')")
                return False
                
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞...")
            self.session = onnxruntime.InferenceSession(
                self.model_path,
                providers=['CPUExecutionProvider']
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–µ –º–æ–¥–µ–ª–∏
            input_cfg = self.session.get_inputs()[0]
            input_shape = input_cfg.shape
            if len(input_shape) >= 4:
                self.input_size = (input_shape[2], input_shape[3])
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞: {self.input_size}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞: {e}")
            logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ (–≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç '—Ä–µ–∞–ª—å–Ω–æ–µ –ª–∏—Ü–æ')")
            return False
    
    def preprocess_face(self, face_image):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ –¥–ª—è –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –º–æ–¥–µ–ª–∏"""
        try:
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            resized = cv2.resize(face_image, self.input_size)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            normalized = resized.astype(np.float32) / 255.0
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏ (1, C, H, W)
            if len(normalized.shape) == 3:
                normalized = np.transpose(normalized, (2, 0, 1))
            normalized = np.expand_dims(normalized, axis=0)
            
            return normalized
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞: {e}")
            return None
    
    def _assess_image_quality(self, face_image):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤"""
        try:
            gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            
            # 1. –†–µ–∑–∫–æ—Å—Ç—å (Laplacian variance)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_norm = min(sharpness / 1000.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            # 2. –ö–æ–Ω—Ç—Ä–∞—Å—Ç (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
            contrast = np.std(gray) / 255.0
            
            # 3. –Ø—Ä–∫–æ—Å—Ç—å (—Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
            brightness = np.mean(gray) / 255.0
            brightness_score = 1.0 - abs(brightness - 0.5) * 2  # –õ—É—á—à–µ –≤—Å–µ–≥–æ —Å—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å
            
            # 4. –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å –æ—Å–≤–µ—â–µ–Ω–∏—è
            lighting_uniformity = 1.0 - (np.std(gray) / np.mean(gray)) if np.mean(gray) > 0 else 0
            lighting_uniformity = max(0, min(1, lighting_uniformity))
            
            # 5. –†–∞–∑–º–µ—Ä –ª–∏—Ü–∞ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)
            face_size = face_image.shape[0] * face_image.shape[1]
            size_score = min(face_size / (200 * 200), 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ 200x200
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            quality_score = (
                sharpness_norm * 0.25 +
                contrast * 0.25 +
                brightness_score * 0.2 +
                lighting_uniformity * 0.15 +
                size_score * 0.15
            )
            
            return {
                "overall_quality": quality_score,
                "sharpness": sharpness_norm,
                "contrast": contrast,
                "brightness": brightness_score,
                "lighting": lighting_uniformity,
                "size_score": size_score,
                "is_high_quality": quality_score > 0.6,
                "is_low_quality": quality_score < 0.3
            }
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return {
                "overall_quality": 0.5,
                "is_high_quality": False,
                "is_low_quality": False
            }

    def predict(self, face_image):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: —Ä–µ–∞–ª—å–Ω–æ–µ –ª–∏—Ü–æ –∏–ª–∏ –ø–æ–¥–¥–µ–ª–∫–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏"""
        if self.session is None:
            # –ó–∞–≥–ª—É—à–∫–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É
            return self._enhanced_fallback_prediction(face_image)
        
        try:
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤
            quality_assessment = self._assess_image_quality(face_image)
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            preprocessed = self.preprocess_face(face_image)
            if preprocessed is None:
                return {"is_real": True, "confidence": 0.0, "error": "–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏"}
            
            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å (–ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å)
            try:
                input_name = self.session.get_inputs()[0].name
                outputs = self.session.run(None, {input_name: preprocessed})
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥–µ–ª–∏
                if len(outputs) > 0 and len(outputs[0]) >= 2:
                    # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: [fake_prob, real_prob]
                    fake_prob = float(outputs[0][0])
                    real_prob = float(outputs[0][1])
                    raw_score = real_prob
                    model_confidence = max(fake_prob, real_prob)
                else:
                    # –û–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ª–∏—Ü–∞)
                    raw_score = float(outputs[0][0]) if len(outputs[0]) > 0 else 0.5
                    model_confidence = abs(raw_score - 0.5) * 2
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                adapted_result = self._adaptive_decision(raw_score, model_confidence, quality_assessment)
                
                # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —è–≤–Ω—ã—Ö –ø–æ–¥–¥–µ–ª–æ–∫ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                if not adapted_result["is_real"] and adapted_result["confidence"] > config.ANTISPOOF_STRICT_THRESHOLD and config.NOTIFY_ON_SPOOFING:
                    telegram_notifier.notify_spoofing_detected("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —è–≤–Ω–∞—è –ø–æ–¥–¥–µ–ª–∫–∞", adapted_result["confidence"])
                
                return {
                    **adapted_result,
                    "error": None,
                    "model_used": "neural_network_adaptive",
                    "quality_assessment": quality_assessment,
                    "raw_model_score": float(raw_score),
                    "model_confidence": float(model_confidence)
                }
                
            except Exception as model_error:
                logger.warning(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞: {model_error}")
                return self._enhanced_fallback_prediction(face_image)
                
        except Exception as e:
            logger.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            telegram_notifier.notify_error("–ê–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –æ—à–∏–±–∫–∞", str(e))
            return {"is_real": True, "confidence": 0.0, "error": str(e)}

    def _adaptive_decision(self, raw_score, model_confidence, quality_assessment):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            quality_score = quality_assessment.get("overall_quality", 0.5)
            is_high_quality = quality_assessment.get("is_high_quality", False)
            is_low_quality = quality_assessment.get("is_low_quality", False)
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if is_low_quality:
                # –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ - –æ—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                threshold = config.LOW_QUALITY_IMAGE_THRESHOLD
                logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥: {threshold}")
            elif is_high_quality:
                # –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥
                threshold = config.HIGH_QUALITY_IMAGE_THRESHOLD
                logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥: {threshold}")
            else:
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
                threshold = config.ANTISPOOF_THRESHOLD * (1 + quality_score * 0.5)
                logger.info(f"–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ ({quality_score:.2f}): {threshold:.3f}")
            
            # –ë–∞–∑–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ
            is_real_base = raw_score > threshold
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
            confidence_penalty = 0.0
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if is_low_quality:
                confidence_penalty += 0.2
                logger.info("–ü—Ä–∏–º–µ–Ω–µ–Ω —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            
            # –ë–æ–Ω—É—Å –∑–∞ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            quality_bonus = quality_score * 0.1
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫
            final_confidence = max(0.0, min(1.0, model_confidence - confidence_penalty + quality_bonus))
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: –±–ª–æ–∫–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            is_real_final = is_real_base or (final_confidence < config.ANTISPOOF_MIN_CONFIDENCE)
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
            logger.info(f"–ê–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ —Ä–µ—à–µ–Ω–∏–µ: raw_score={raw_score:.3f}, threshold={threshold:.3f}, "
                       f"model_confidence={model_confidence:.3f}, final_confidence={final_confidence:.3f}, "
                       f"is_real={is_real_final}")
            
            return {
                "is_real": is_real_final,
                "confidence": float(final_confidence),
                "score": float(raw_score),
                "decision_threshold": float(threshold),
                "quality_bonus": float(quality_bonus),
                "confidence_penalty": float(confidence_penalty)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (—Å—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–º)
            return {
                "is_real": True,
                "confidence": 0.5,
                "score": float(raw_score),
                "error": str(e)
            }
    
    def _enhanced_fallback_prediction(self, face_image):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            quality_assessment = self._assess_image_quality(face_image)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            
            # 1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã (—Ä–∞—Å—á–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
            texture_score = np.std(gray) / 255.0
            
            # 2. –ê–Ω–∞–ª–∏–∑ –∫—Ä–∞–µ–≤ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑–∫–∏—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
            
            # 3. –ê–Ω–∞–ª–∏–∑ —è—Ä–∫–æ—Å—Ç–∏ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å –æ—Å–≤–µ—â–µ–Ω–∏—è)
            brightness_var = np.var(gray) / (255.0 ** 2)
            
            # 4. –ê–Ω–∞–ª–∏–∑ LBP (Local Binary Patterns) –¥–ª—è —Ç–µ–∫—Å—Ç—É—Ä—ã
            lbp_score = self._calculate_lbp_score(gray)
            
            # 5. –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (FFT)
            frequency_score = self._calculate_frequency_score(gray)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä —Å —É—á–µ—Ç–æ–º –Ω–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
            combined_score = (
                texture_score * 0.25 +
                edge_density * 0.25 +
                brightness_var * 0.15 +
                lbp_score * 0.2 +
                frequency_score * 0.15
            )
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if quality_assessment.get("is_low_quality", False):
                threshold = 0.15  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –¥–ª—è –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                logger.info("Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
            elif quality_assessment.get("is_high_quality", False):
                threshold = 0.4   # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                logger.info("Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
            else:
                threshold = 0.25  # –°—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥
                logger.info("Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥")
            
            # –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞
            is_real = combined_score > threshold
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
            base_confidence = min(combined_score * 2, 1.0)
            quality_bonus = quality_assessment.get("overall_quality", 0.5) * 0.1
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –¥–ª—è fallback)
            final_confidence = max(0.1, min(0.7, base_confidence + quality_bonus))
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ fallback —Ä–µ—à–µ–Ω–∏—è
            logger.info(f"Fallback –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥: combined_score={combined_score:.3f}, "
                       f"threshold={threshold:.3f}, is_real={is_real}, confidence={final_confidence:.3f}")
            
            return {
                "is_real": is_real,
                "confidence": float(final_confidence),
                "score": float(combined_score),
                "error": None,
                "model_used": "enhanced_heuristic_fallback",
                "quality_assessment": quality_assessment,
                "decision_threshold": float(threshold),
                "details": {
                    "texture_score": float(texture_score),
                    "edge_density": float(edge_density),
                    "brightness_var": float(brightness_var),
                    "lbp_score": float(lbp_score),
                    "frequency_score": float(frequency_score)
                }
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞: {e}")
            return {
                "is_real": True,
                "confidence": 0.5,
                "score": 0.5,
                "error": str(e),
                "model_used": "default_safe"
            }

    def _calculate_lbp_score(self, gray_image):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Local Binary Patterns"""
        try:
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è LBP
            height, width = gray_image.shape
            lbp_values = []
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Å —à–∞–≥–æ–º (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            for y in range(1, height - 1, 4):
                for x in range(1, width - 1, 4):
                    center = gray_image[y, x]
                    binary_pattern = 0
                    
                    # 8-—Å–æ—Å–µ–¥–Ω–∏–π LBP
                    neighbors = [
                        gray_image[y-1, x-1], gray_image[y-1, x], gray_image[y-1, x+1],
                        gray_image[y, x+1], gray_image[y+1, x+1], gray_image[y+1, x],
                        gray_image[y+1, x-1], gray_image[y, x-1]
                    ]
                    
                    for i, neighbor in enumerate(neighbors):
                        if neighbor >= center:
                            binary_pattern |= (1 << i)
                    
                    lbp_values.append(binary_pattern)
            
            if len(lbp_values) == 0:
                return 0.5
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            unique_patterns = len(set(lbp_values))
            pattern_diversity = min(unique_patterns / 100.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            return pattern_diversity
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è LBP: {e}")
            return 0.5

    def _calculate_frequency_score(self, gray_image):
        """–ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ—Ä–µ–∑ FFT"""
        try:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º FFT
            fft = np.fft.fft2(gray_image)
            fft_shift = np.fft.fftshift(fft)
            magnitude_spectrum = np.abs(fft_shift)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç
            height, width = magnitude_spectrum.shape
            center_y, center_x = height // 2, width // 2
            
            # –í—ã—Å–æ–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã (–¥–∞–ª—å—à–µ –æ—Ç —Ü–µ–Ω—Ç—Ä–∞)
            high_freq_mask = np.zeros_like(magnitude_spectrum)
            y, x = np.ogrid[:height, :width]
            distance = np.sqrt((y - center_y)**2 + (x - center_x)**2)
            high_freq_mask[distance > min(height, width) * 0.3] = 1
            
            high_freq_energy = np.sum(magnitude_spectrum * high_freq_mask)
            total_energy = np.sum(magnitude_spectrum)
            
            if total_energy > 0:
                high_freq_ratio = high_freq_energy / total_energy
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç –±–æ–ª—å—à–µ –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç)
                frequency_score = min(high_freq_ratio * 10, 1.0)
            else:
                frequency_score = 0.5
            
            return frequency_score
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–æ—Ç: {e}")
            return 0.5

    def _fallback_prediction(self, face_image):
        """–ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        return self._enhanced_fallback_prediction(face_image)

# –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MagFace
class MagFaceProcessor:
    def __init__(self):
        self.app = None
        self.antispoof = AntiSpoofProcessor()
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ MagFace"""
        try:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ MagFace –º–æ–¥–µ–ª–∏...")
            self.app = insightface.app.FaceAnalysis(
                providers=['CPUExecutionProvider'],
                allowed_modules=['detection', 'recognition']
            )
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            self.app.prepare(ctx_id=0, det_size=(640, 640))
            logger.info("‚úÖ MagFace –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MagFace: {e}")
            raise
    
    def preprocess_image(self, image):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if len(image.shape) == 3 and image.shape[2] == 3:
                # BGR to RGB –¥–ª—è OpenCV
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            elif len(image.shape) == 3 and image.shape[2] == 4:
                # RGBA to RGB
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            elif len(image.shape) == 2:
                # Grayscale to RGB
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
            height, width = image.shape[:2]
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ
            min_size = 300
            if min(height, width) < min_size:
                scale = min_size / min(height, width)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                logger.info(f"–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {width}x{height} -> {new_width}x{new_height}")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            max_size = 1920
            if max(height, width) > max_size:
                scale = max_size / max(height, width)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
                logger.info(f"–£–º–µ–Ω—å—à–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {width}x{height} -> {new_width}x{new_height}")
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ –∏ —è—Ä–∫–æ—Å—Ç–∏
            # –ü—Ä–∏–º–µ–Ω—è–µ–º CLAHE (Contrast Limited Adaptive Histogram Equalization)
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            lab[:,:,0] = clahe.apply(lab[:,:,0])
            image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ BGR –¥–ª—è InsightFace
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            return image
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return image

    def detect_faces_multiple_attempts(self, image):
        """–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        attempts = [
            (640, 640, 0.1),   # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            (320, 320, 0.05),  # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            (512, 512, 0.2),   # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            (1024, 1024, 0.3), # –°—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥
            (800, 800, 0.15),  # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π
            (480, 480, 0.1),   # –ú–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–º–µ—Ä
        ]
        
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –ª–∏—Ü, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫: {len(attempts)}")
        
        for i, (det_size_w, det_size_h, threshold) in enumerate(attempts, 1):
            try:
                logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {i}/{len(attempts)}: det_size=({det_size_w},{det_size_h}), threshold={threshold}")
                
                # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
                self.app.prepare(ctx_id=0, det_size=(det_size_w, det_size_h))
                
                faces = self.app.get(image)
                logger.info(f"MagFace –≤–µ—Ä–Ω—É–ª {len(faces) if faces else 0} –ª–∏—Ü")
                
                if faces and len(faces) > 0:
                    # –ü—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±—ã–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞
                    valid_faces = []
                    for j, face in enumerate(faces):
                        bbox = face.bbox
                        face_width = bbox[2] - bbox[0]
                        face_height = bbox[3] - bbox[1]
                        logger.info(f"–õ–∏—Ü–æ {j+1}: —Ä–∞–∑–º–µ—Ä {face_width:.1f}x{face_height:.1f}")
                        
                        # –û—á–µ–Ω—å –º—è–≥–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è - –ª–∏—Ü–æ —Ö–æ—Ç—è –±—ã 20x20 –ø–∏–∫—Å–µ–ª–µ–π
                        if face_width >= 20 and face_height >= 20:
                            valid_faces.append(face)
                    
                    if valid_faces:
                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ª–∏—Ü–∞ –ø–æ —Ä–∞–∑–º–µ—Ä—É (–ø–ª–æ—â–∞–¥–∏) - —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ø–µ—Ä–≤—ã–º
                        valid_faces.sort(key=lambda face: (face.bbox[2] - face.bbox[0]) * (face.bbox[3] - face.bbox[1]), reverse=True)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ª–∏—Ü–∞—Ö
                        for j, face in enumerate(valid_faces):
                            bbox = face.bbox
                            area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                            logger.info(f"–õ–∏—Ü–æ {j+1}: –ø–ª–æ—â–∞–¥—å {area:.0f} –ø–∏–∫—Å–µ–ª–µ–π, bbox={bbox}")
                        
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(valid_faces)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ª–∏—Ü –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {i}, –≤—ã–±—Ä–∞–Ω–æ —Å–∞–º–æ–µ –∫—Ä—É–ø–Ω–æ–µ")
                        return valid_faces
                        
            except Exception as e:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {i} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –æ—à–∏–±–∫–æ–π: {e}")
                continue
        
        logger.warning("‚ùå –õ–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –≤ –æ–¥–Ω–æ–π –∏–∑ –ø–æ–ø—ã—Ç–æ–∫")
        return []

    def detect_faces_opencv_fallback(self, image):
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —á–µ—Ä–µ–∑ OpenCV –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å"""
        try:
            logger.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü —á–µ—Ä–µ–∑ OpenCV Haar Cascades")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Å–∫–∞–¥ –•–∞–∞—Ä–∞
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            for scale_factor in [1.1, 1.05, 1.2, 1.3]:
                for min_neighbors in [3, 2, 5, 1]:
                    faces = face_cascade.detectMultiScale(
                        gray,
                        scaleFactor=scale_factor,
                        minNeighbors=min_neighbors,
                        minSize=(30, 30)
                    )
                    
                    if len(faces) > 0:
                        logger.info(f"‚úÖ OpenCV –Ω–∞—à–µ–ª {len(faces)} –ª–∏—Ü —Å–æ scale_factor={scale_factor}, min_neighbors={min_neighbors}")
                        return faces
            
            logger.warning("‚ùå OpenCV –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –ª–∏—Ü–∞")
            return []
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü —á–µ—Ä–µ–∑ OpenCV: {e}")
            return []

    def extract_embeddings_from_opencv_faces(self, image, opencv_faces):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –ª–∏—Ü, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö OpenCV"""
        try:
            logger.info(f"üîÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ {len(opencv_faces)} –ª–∏—Ü, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö OpenCV")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ª–∏—Ü–∞ –ø–æ –ø–ª–æ—â–∞–¥–∏ (—Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ø–µ—Ä–≤—ã–º)
            faces_with_area = []
            for (x, y, w, h) in opencv_faces:
                area = w * h
                faces_with_area.append(((x, y, w, h), area))
            
            faces_with_area.sort(key=lambda x: x[1], reverse=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –ª–∏—Ü–æ, –Ω–∞—á–∏–Ω–∞—è —Å —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ
            for i, ((x, y, w, h), area) in enumerate(faces_with_area):
                try:
                    logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ {i+1}/{len(faces_with_area)}: –ø–æ–∑–∏—Ü–∏—è ({x},{y}), —Ä–∞–∑–º–µ—Ä {w}x{h}, –ø–ª–æ—â–∞–¥—å {area}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (15% –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–∏—Ü–∞)
                    padding_x = int(w * 0.15)
                    padding_y = int(h * 0.15)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏
                    x1 = max(0, x - padding_x)
                    y1 = max(0, y - padding_y)
                    x2 = min(image.shape[1], x + w + padding_x)
                    y2 = min(image.shape[0], y + h + padding_y)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏
                    face_crop = image[y1:y2, x1:x2]
                    
                    if face_crop.size == 0:
                        logger.warning(f"–ü—É—Å—Ç–∞—è –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ {i+1}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    logger.info(f"–û–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ {i+1}: {face_crop.shape}, –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: ({x1},{y1},{x2},{y2})")
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å InsightFace –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞
                    try:
                        # –í—Ä–µ–º–µ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
                        original_det_size = (640, 640)
                        
                        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏
                        self.app.prepare(ctx_id=0, det_size=(320, 320))
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞
                        insight_faces = self.app.get(face_crop)
                        
                        if insight_faces and len(insight_faces) > 0:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
                            insight_face = insight_faces[0]
                            
                            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º bbox –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                            original_bbox = np.array([
                                x1 + insight_face.bbox[0],
                                y1 + insight_face.bbox[1], 
                                x1 + insight_face.bbox[2],
                                y1 + insight_face.bbox[3]
                            ])
                            
                            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –ª–∏—Ü–∞ {i+1} —á–µ—Ä–µ–∑ InsightFace")
                            
                            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
                            self.app.prepare(ctx_id=0, det_size=original_det_size)
                            
                            return {
                                "embedding": insight_face.embedding,
                                "bbox": original_bbox,
                                "det_score": insight_face.det_score,
                                "detection_method": "opencv_assisted_insightface",
                                "face_crop_coords": (x1, y1, x2, y2),
                                "original_opencv_bbox": (x, y, w, h)
                            }
                            
                        else:
                            logger.warning(f"InsightFace –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ {i+1}")
                            
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Ü–∞ {i+1} —á–µ—Ä–µ–∑ InsightFace: {e}")
                        continue
                    
                    finally:
                        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                        try:
                            self.app.prepare(ctx_id=0, det_size=original_det_size)
                        except:
                            pass
                            
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Ü–∞ {i+1}: {e}")
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–æ –ª–∏—Ü–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥
            logger.warning("‚ö†Ô∏è InsightFace –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ –ª–∏—Ü–æ –∏–∑ OpenCV, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É")
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ª–∏—Ü–æ –¥–ª—è –∑–∞–≥–ª—É—à–∫–∏
            (x, y, w, h), _ = faces_with_area[0]
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ª–∏—Ü–∞
            fake_embedding = self._generate_fallback_embedding(image, x, y, w, h)
            
            return {
                "embedding": fake_embedding,
                "bbox": np.array([x, y, x+w, y+h], dtype=np.float32),
                "det_score": 0.5,  # –°—Ä–µ–¥–Ω–∏–π score –¥–ª—è OpenCV
                "detection_method": "opencv_fallback",
                "warning": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
            }
            
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ OpenCV –ª–∏—Ü: {e}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ª–∏—Ü: {e}")

    def _generate_fallback_embedding(self, image, x, y, w, h):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è fallback —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞
            face_crop = image[y:y+h, x:x+w]
            
            if face_crop.size == 0:
                # –ï—Å–ª–∏ –æ–±–ª–∞—Å—Ç—å –ø—É—Å—Ç–∞—è, —Å–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
                embedding = np.random.normal(0, 0.1, 512).astype(np.float32)
                return embedding / np.linalg.norm(embedding)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            if len(face_crop.shape) == 3:
                gray_face = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_crop
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            features = []
            
            # 1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —è—Ä–∫–æ—Å—Ç–∏
            features.extend([
                np.mean(gray_face) / 255.0,
                np.std(gray_face) / 255.0,
                np.median(gray_face) / 255.0,
                (np.max(gray_face) - np.min(gray_face)) / 255.0
            ])
            
            # 2. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
            hist, _ = np.histogram(gray_face, bins=16, range=(0, 256))
            hist_norm = hist / np.sum(hist)
            features.extend(hist_norm.tolist())
            
            # 3. –¢–µ–∫—Å—Ç—É—Ä–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            # –õ–æ–∫–∞–ª—å–Ω—ã–µ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            try:
                # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                grad_x = cv2.Sobel(gray_face, cv2.CV_64F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(gray_face, cv2.CV_64F, 0, 1, ksize=3)
                
                features.extend([
                    np.mean(np.abs(grad_x)) / 255.0,
                    np.mean(np.abs(grad_y)) / 255.0,
                    np.std(grad_x) / 255.0,
                    np.std(grad_y) / 255.0
                ])
            except:
                features.extend([0.1, 0.1, 0.1, 0.1])
            
            # 4. –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            features.extend([
                w / max(image.shape[:2]),  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞
                h / max(image.shape[:2]),  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞
                (w * h) / (image.shape[0] * image.shape[1]),  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å
                w / h if h > 0 else 1.0  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
            ])
            
            # 5. –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            features.extend([
                x / image.shape[1],  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è X
                y / image.shape[0],  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è Y
                (x + w/2) / image.shape[1],  # –¶–µ–Ω—Ç—Ä X
                (y + h/2) / image.shape[0]   # –¶–µ–Ω—Ç—Ä Y
            ])
            
            # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–æ 512 –∏–∑–º–µ—Ä–µ–Ω–∏–π
            current_size = len(features)
            if current_size < 512:
                # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                repeat_count = (512 - current_size) // current_size
                remainder = (512 - current_size) % current_size
                
                for i in range(repeat_count):
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
                    modified_features = [f * (1 + 0.1 * np.sin(i * np.pi + j)) for j, f in enumerate(features)]
                    features.extend(modified_features)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                if remainder > 0:
                    features.extend(features[:remainder])
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ç–æ—á–Ω–æ 512 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            features = features[:512]
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            embedding = np.array(features, dtype=np.float32)
            
            # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            else:
                # –ï—Å–ª–∏ –Ω–æ—Ä–º–∞ 0, —Å–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
                embedding = np.random.normal(0, 0.1, 512).astype(np.float32)
                embedding = embedding / np.linalg.norm(embedding)
            
            logger.info(f"–°–æ–∑–¥–∞–Ω fallback —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {len(embedding)} —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(embedding):.3f}")
            
            return embedding
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è fallback —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = np.random.normal(0, 0.1, 512).astype(np.float32)
            return embedding / np.linalg.norm(embedding)

    def extract_face_embeddings(self, image, enable_antispoof=True):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ª–∏—Ü —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–æ–º"""
        try:
            start_time = time.time()
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            processed_image = self.preprocess_image(image)
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —á–µ—Ä–µ–∑ InsightFace
            faces = self.detect_faces_multiple_attempts(processed_image)
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            embedding_result = None
            detection_method = "insightface"
            
            if faces:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º InsightFace —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                main_face = faces[0]
                bbox = main_face.bbox
                face_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–æ –ª–∏—Ü–æ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –ø–ª–æ—â–∞–¥—å—é: {face_area:.0f} –ø–∏–∫—Å–µ–ª–µ–π –∏–∑ {len(faces)} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö")
                
                embedding_result = {
                    "embedding": main_face.embedding,
                    "bbox": main_face.bbox,
                    "det_score": main_face.det_score,
                    "detection_method": "insightface"
                }
                
            else:
                # –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ OpenCV + InsightFace –≥–∏–±—Ä–∏–¥
                logger.info("üîÑ InsightFace –Ω–µ –Ω–∞—à–µ–ª –ª–∏—Ü–∞, –ø—Ä–æ–±—É–µ–º OpenCV + InsightFace –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
                opencv_faces = self.detect_faces_opencv_fallback(processed_image)
                
                if len(opencv_faces) == 0:
                    raise ValueError("–õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ OpenCV –ª–∏—Ü —á–µ—Ä–µ–∑ InsightFace
                embedding_result = self.extract_embeddings_from_opencv_faces(processed_image, opencv_faces)
                detection_method = embedding_result.get("detection_method", "opencv_hybrid")
            
            # –ê–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –ø—Ä–æ–≤–µ—Ä–∫–∞
            antispoof_result = None
            if enable_antispoof and embedding_result:
                try:
                    bbox = embedding_result["bbox"].astype(int)
                    x1, y1, x2, y2 = bbox
                    face_crop = processed_image[y1:y2, x1:x2]
                    
                    if face_crop.size > 0:
                        antispoof_result = self.antispoof.predict(face_crop)
                        app_stats["total_antispoof_checks"] += 1
                        
                        if antispoof_result.get("is_real", True):
                            app_stats["real_faces"] += 1
                        else:
                            app_stats["fake_faces"] += 1
                            
                        logger.info(f"–ê–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {antispoof_result}")
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞: {e}")
                    antispoof_result = {"is_real": True, "confidence": 0.0, "error": str(e)}
            
            processing_time = time.time() - start_time
            logger.info(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processing_time:.3f} —Å–µ–∫, –º–µ—Ç–æ–¥: {detection_method}")
            
            return {
                "embedding": embedding_result["embedding"],
                "bbox": embedding_result["bbox"],
                "det_score": embedding_result.get("det_score", 0.5),
                "processing_time": processing_time,
                "faces_count": 1,
                "detection_method": detection_method,
                "antispoof": antispoof_result
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}")
            raise

    def compare_faces(self, image1, image2, enable_antispoof=True, threshold=0.5, metric="cosine"):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ª–∏—Ü —Å –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–æ–º"""
        start_time = time.time()
        
        try:
            app_stats["total_comparisons"] += 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
            result1 = self.extract_face_embeddings(image1, enable_antispoof=False)  # –ü–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞
            result2 = self.extract_face_embeddings(image2, enable_antispoof=enable_antispoof)  # –í—Ç–æ—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–æ–º
            
            embedding1 = result1["embedding"]
            embedding2 = result2["embedding"]
            faces1_count = result1.get("faces_count", 1)
            faces2_count = result2.get("faces_count", 1)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏
            if metric == "cosine":
                similarity = np.dot(embedding1, embedding2) / (
                    np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
                )
                distance = 1 - similarity
            elif metric == "euclidean":
                distance = np.linalg.norm(embedding1 - embedding2)
                similarity = 1 / (1 + distance)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–¥—Å—Ç–≤–æ
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
                similarity = np.dot(embedding1, embedding2) / (
                    np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
                )
                distance = 1 - similarity
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
            verified = similarity > threshold
            
            processing_time = time.time() - start_time
            app_stats["response_times"].append(processing_time)
            
            if verified:
                app_stats["successful_comparisons"] += 1
            else:
                app_stats["failed_comparisons"] += 1
            
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è numpy —Ç–∏–ø–æ–≤ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã
            def convert_numpy_types(obj):
                """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã"""
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.bool_):
                    return bool(obj)
                elif isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                else:
                    return obj
            
            result = {
                "verified": bool(verified),
                "distance": float(distance),
                "similarity": float(similarity),
                "threshold": float(threshold),
                "processing_time": float(processing_time),
                "model": "MagFace-R100",
                "metric": str(metric),
                "similarity_percentage": float(round(similarity * 100, 2)),
                "timestamp": datetime.now().isoformat(),
                "faces_detected": {
                    "image1": int(faces1_count),
                    "image2": int(faces2_count)
                }
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
            if enable_antispoof:
                # –û—á–∏—â–∞–µ–º –æ—Ç numpy —Ç–∏–ø–æ–≤ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
                antispoof2 = result2.get("antispoof")
                
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç None, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                if antispoof2 is None:
                    antispoof2 = {"is_real": True, "confidence": 0.0, "error": "No antispoof result"}
                
                antispoof_data = {
                    "image1": {"is_real": True, "confidence": 0.0, "note": "–ê–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"},
                    "image2": convert_numpy_types(antispoof2)
                }
                result["antispoof_results"] = antispoof_data
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            logger.info(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: similarity={similarity:.3f}, verified={verified}")
            
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∏–∑ endpoint'–∞ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            
            return result
            
        except Exception as e:
            app_stats["failed_comparisons"] += 1
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü: {str(e)}")
            raise

    def download_image_from_url(self, url: str) -> np.ndarray:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ URL"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ URL: {url[:100]}...")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
            parsed_url = urlparse(url)
            if not parsed_url.scheme or not parsed_url.netloc:
                raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=30, stream=True)
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_type = response.headers.get('content-type', '')
            if not content_type.startswith('image/'):
                logger.warning(f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π content-type: {content_type}")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            image_data = response.content
            if len(image_data) > 50 * 1024 * 1024:  # 50MB –ª–∏–º–∏—Ç
                raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (>50MB)")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy array
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            
            logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {image.shape}")
            return image
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(e)}")

    def decode_base64_image(self, base64_string: str) -> np.ndarray:
        """–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ base64"""
        try:
            logger.info(f"–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–ª–∏–Ω–∞: {len(base64_string)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å data:image –µ—Å–ª–∏ –µ—Å—Ç—å
            if ',' in base64_string:
                base64_string = base64_string.split(',')[1]
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
            image_data = base64.b64decode(base64_string)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image
            pil_image = Image.open(io.BytesIO(image_data))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array (BGR –¥–ª—è OpenCV)
            image_array = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            return image_array
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(e)}")

    def load_image(self, image_data: str, image_type: str = "base64") -> np.ndarray:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∏–ø–∞: {image_type}, –¥–∞–Ω–Ω—ã–µ: {image_data[:50]}...")
        
        if image_type == "url":
            return self.download_image_from_url(image_data)
        elif image_type == "base64":
            return self.decode_base64_image(image_data)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_type}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'base64' –∏–ª–∏ 'url'")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –ª–∏—Ü
face_processor = MagFaceProcessor()

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="Face Comparison Service with Anti-Spoofing",
    description="–°–µ—Ä–≤–∏—Å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MagFace –º–æ–¥–µ–ª–∏ –∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup_event():
    """–°–æ–±—ã—Ç–∏–µ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Face Comparison Service —Å MagFace –∏ Anti-Spoofing")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    success = face_processor._load_model()
    if success:
        logger.info("‚úÖ –°–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
    else:
        logger.warning("‚ö†Ô∏è –°–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω, –Ω–æ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

@app.get("/", response_model=Dict[str, str])
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "message": "Face Comparison Service with Anti-Spoofing",
        "version": "2.0.0",
        "status": "running",
        "model": "MagFace-R100 with Anti-Spoofing",
        "docs": "/docs"
    }

@app.get("/api/v1/health", response_model=HealthResponse)
async def health_check():
    """Health check —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    uptime = (datetime.now() - app_stats["start_time"]).total_seconds()
    
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        uptime_seconds=uptime,
        total_comparisons=app_stats["total_comparisons"],
        total_antispoof_checks=app_stats["total_antispoof_checks"],
        gpu_available=False,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –≤–µ—Ä—Å–∏—é
        models_loaded=face_processor.app is not None
    )

@app.get("/api/v1/info", response_model=SystemInfoResponse)
async def system_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ"""
    return SystemInfoResponse(
        service_name="Face Comparison Service with Anti-Spoofing",
        version="2.0.0",
        model="MagFace-R100",
        available_models=["MagFace-R100"],
        supported_formats=["JPEG", "PNG", "BMP", "TIFF"],
        gpu_info={"gpu_available": False, "using_cpu": True},
        configuration={
            "model": "MagFace-R100",
            "antispoof_model": "ASV Anti-Spoof R34",
            "backend": "ONNX Runtime",
            "device": "CPU"
        },
        antispoof_enabled=face_processor.antispoof.session is not None
    )

@app.post("/api/v1/compare", response_model=CompareResponse)
async def compare_faces(request: CompareRequest):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ª–∏—Ü —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π URL, base64 –∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞"""
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–∏—Ü —Å –º–æ–¥–µ–ª—å—é {request.model}, –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥: {request.enable_antispoof}")
        app_stats["total_comparisons"] += 1
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image1 = face_processor.load_image(request.image1, request.image1_type)
        image2 = face_processor.load_image(request.image2, request.image2_type)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ª–∏—Ü–∞
        result = face_processor.compare_faces(
            image1, 
            image2, 
            enable_antispoof=request.enable_antispoof,
            threshold=request.threshold,
            metric=request.metric
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ—É—Å–ø–µ—à–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if not result["verified"]:
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                img1_url = request.image1 if request.image1_type == "url" else None
                img2_url = request.image2 if request.image2_type == "url" else None
                
                telegram_notifier.notify_comparison_result(
                    similarity=result["similarity"], 
                    verified=result["verified"], 
                    processing_time=result["processing_time"],
                    image1_url=img1_url,
                    image2_url=img2_url,
                    antispoof_results=result.get("antispoof_results"),
                    threshold=result["threshold"]
                )
                logger.info("üì§ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ - –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")
            except Exception as notify_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {notify_error}")
        else:
            logger.info("‚úÖ –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è")
        
        return result
        
    except Exception as e:
        app_stats["failed_comparisons"] += 1
        logger.error(f"–û—à–∏–±–∫–∞ –≤ endpoint compare_faces: {str(e)}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        try:
            telegram_notifier.notify_error("API Error", str(e))
        except Exception as notify_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ: {notify_error}")
        
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        result.update({
            "model": request.model,
            "metric": request.metric,
            "threshold": request.threshold if request.threshold else result["threshold"],
            "similarity_percentage": round(result["similarity"] * 100, 2),
            "timestamp": datetime.now().isoformat(),
            "faces_detected": {"image1": 1, "image2": 1}
        })
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/v1/models")
async def get_models():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    return {
        "models": ["MagFace-R100"],
        "current_model": "MagFace-R100",
        "antispoof_model": "ASV Anti-Spoof R34",
        "backend": "ONNX Runtime",
        "note": "Using MagFace R100 implementation with anti-spoofing"
    }

@app.get("/api/v1/status")
async def get_status():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–∏—Å–∞"""
    uptime = (datetime.now() - app_stats["start_time"]).total_seconds()
    
    avg_response_time = (
        sum(app_stats["response_times"][-100:]) / len(app_stats["response_times"][-100:])
        if app_stats["response_times"] else 0
    )
    
    return {
        "service": "Face Comparison Service with Anti-Spoofing",
        "version": "2.0.0",
        "model": "MagFace-R100",
        "antispoof_model": "ASV Anti-Spoof R34",
        "uptime_seconds": uptime,
        "uptime_formatted": str(datetime.now() - app_stats["start_time"]),
        "gpu_available": False,
        "models_loaded": face_processor.app is not None,
        "antispoof_loaded": face_processor.antispoof.session is not None,
        "statistics": {
            "total_comparisons": app_stats["total_comparisons"],
            "successful_comparisons": app_stats["successful_comparisons"],
            "failed_comparisons": app_stats["failed_comparisons"],
            "total_antispoof_checks": app_stats["total_antispoof_checks"],
            "real_faces": app_stats["real_faces"],
            "fake_faces": app_stats["fake_faces"],
            "success_rate": (
                app_stats["successful_comparisons"] / app_stats["total_comparisons"] * 100
                if app_stats["total_comparisons"] > 0 else 0
            ),
            "average_response_time": round(avg_response_time, 3)
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/v1/test-notifications")
async def test_notifications():
    """–¢–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å –ø—Ä–∏–º–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö
        telegram_notifier.notify_comparison_result(
            similarity=0.25,
            verified=False,
            processing_time=0.5,
            image1_url="https://example.com/image1.jpg",
            image2_url="https://example.com/image2.jpg",
            antispoof_results={
                "image1": {"is_real": False, "confidence": 0.8},
                "image2": {"is_real": True, "confidence": 0.9}
            },
            threshold=0.5
        )
        
        return {
            "message": "–¢–µ—Å—Ç–æ–≤–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram",
            "status": "ok",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "message": f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {str(e)}",
            "status": "error",
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/v1/antispoof")
async def check_antispoof(request: dict):
    """–û—Ç–¥–µ–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥–∞"""
    try:
        image_data = request.get("image")
        image_type = request.get("image_type", "base64")
        
        if not image_data:
            raise HTTPException(status_code=400, detail="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = face_processor.load_image(image_data, image_type)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–∏—Ü–æ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥
        result = face_processor.extract_face_embeddings(image, enable_antispoof=True)
        
        return {
            "antispoof_result": result.get("antispoof"),
            "faces_detected": result.get("faces_count", 0),
            "processing_time": result.get("processing_time", 0),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω—Ç–∏—Å–ø—É—Ñ–∏–Ω–≥ –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    os.makedirs("./logs", exist_ok=True)
    os.makedirs("./models", exist_ok=True)
    
    logger.info("–ó–∞–ø—É—Å–∫ Face Comparison Service —Å MagFace –∏ Anti-Spoofing")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True
    ) 